---
title: 'Mastering the Game of Go without Human Knowledge'
date: 2023-11-20
permalink: /posts/2012/08/blog-post-1/
tags:
  - Go
  - AlphaGo
  - Reinforcement Learning
  - Deep Learning
  - Machine Learning
  - Artificial Intelligence
  - Game Theory
  - Monte Carlo Tree Search
  - Neural Networks
  - Convolutional Neural Networks
---


What is Go?
======
Go is a board game that originated in China more than 2,500 years ago. The game is played by two players who take turns placing black and white stones on a 19x19 grid. The goal of the game is to surround more territory than your opponent. The game is considered to be one of the most complex board games in the world. The number of possible board positions is estimated to be 10^170. For comparison, the number of atoms in the observable universe is estimated to be 10^80. 

Why is Go important?
======



Challenges with state of the art
======
The state of the art in Go is to use Monte Carlo Tree Search (MCTS) to search for the best move. MCTS is a heuristic search algorithm that uses random sampling to search for the best move. The algorithm is based on the idea that the best move is the one that leads to the most wins. 

How did DeepMind solve the problem?
======
DeepMind used a combination of supervised learning and reinforcement learning to train a neural network to play Go.


Which Data was used to train and evaluate the model? How was it collected?
======
The data used to train and evaluate the model was collected from the game of Go. 


Input and output representation
======
The input to the model is a 19x19x17 matrix. The first 17 channels represent the board state. The last channel represents the current player. The output of the model is a 19x19 matrix. Each element in the matrix represents the probability of the current player playing a stone at that position. The model is trained using a combination of supervised learning and reinforcement learning. The model is traine


Deep Learning Architecture
======
The model is a convolutional neural network with 40 layers. 


Results
====== 



Discussion
======



Acknowledgements
======
I would like to thank Prof. Dr. Mathias Niepert and M.Sc. Marimuthu Kalimuthu, for their guidance and support throughout this project. I would also like to thank my family for their support and encouragement.


References
======
https://www.youtube.com/watch?v=Z1BELqFQZVM

https://www.youtube.com/watch?v=0slFo1rV0EM&list=WL&index=49&pp=gAQBiAQB
