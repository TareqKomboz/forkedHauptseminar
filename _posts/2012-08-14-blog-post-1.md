---
title: 'Mastering the Game of Go without Human Knowledge'
date: 2023-11-20
permalink: /posts/2012/08/blog-post-1/
tags:
  - Go
  - AlphaGo
  - Reinforcement Learning
  - Deep Learning
  - Machine Learning
  - Artificial Intelligence
  - Game Theory
  - Monte Carlo Tree Search
  - Neural Networks
  - Convolutional Neural Networks
---


Go is interesting
======
Go is a board game that originated in China more than 2,500 years ago. The game is played by two players who take turns placing black and white stones on a 19x19 grid. The goal of the game is to surround more territory than your opponent. The game is considered to be one of the most complex board games in the world. The number of possible board positions is estimated to be 10^170. For comparison, the number of atoms in the observable universe is estimated to be 10^80. Globally it is played by over 40 million people.

We can represent Go Positions Compactly
======
Input 17 x 19 x 19
One 19 x 19 feature map for white
One 19 x 19 feature map for black
Seven past board states for both colors
One 19 x 19 feature map indicating whos move it is


Input and output representation
======
The input to the model is a 19x19x17 matrix. The first 17 channels represent the board state. The last channel represents the current player. The output of the model is a 19x19 matrix. Each element in the matrix represents the probability of the current player playing a stone at that position. The model is trained using a combination of supervised learning and reinforcement learning.

Deep Learning Architecture
======


Basic Cnn Example
======

<figure>
  <img src="https://tareqkomboz.github.io/forkedHauptseminar/images/CNN.jpg" alt="CNN Image"/>
  <figcaption>Source: https://de.mathworks.com/discovery/convolutional-neural-network-matlab.html</figcaption>
</figure>

![CNN Image](https://tareqkomboz.github.io/forkedHauptseminar/images/CNN.jpg)
Source: https://de.mathworks.com/discovery/convolutional-neural-network-matlab.html

Mapping Go to a Deep Learning Problem
======
![Image of Policy and Value Network](https://tareqkomboz.github.io/forkedHauptseminar/images/Policy_Value_Network.png)
Source: Silver, David et al., 2017

How AlphaGo was trained
======
![Image of AlphaGo Training](https://tareqkomboz.github.io/forkedHauptseminar/images/AlphaGo_TrainingAndEvaluation.png)
Source: Silver, David et al., 2017

Exhaustive Search is not feasible
======
![Image of Exhaustive Search](https://tareqkomboz.github.io/forkedHauptseminar/images/ExhaustiveSearch.png)
Source: Silver, David et al., 2017

Use the Policy Network to reduce the breadth
======
![Image of Policy Network](https://tareqkomboz.github.io/forkedHauptseminar/images/PolicyNetwork.png)
Source: Silver, David et al., 2017

Use the Value Network to reduce the depth
======
![Image of Value Network](https://tareqkomboz.github.io/forkedHauptseminar/images/ValueNetwork.png)
Source: Silver, David et al., 2017

AlphaGo uses Monte Carlo Tree Search
======
![Image of Monte Carlo Tree Search](https://tareqkomboz.github.io/forkedHauptseminar/images/MCTS.png)
Source: Silver, David et al., 2017

AlphaGo achieved superhuman performance
======
![Image of AlphaGo Performance](https://tareqkomboz.github.io/forkedHauptseminar/images/LeeSedol.png)
Source: Silver, David et al., 2017

![Image of AlphaGo Performance](https://tareqkomboz.github.io/forkedHauptseminar/images/KeJie_Half.png)
Source: Silver, David et al., 2017

AlhpaGo Lee in March 2016
AlphaGo Master in May 2017
AlphaGo Zero in October 2017

AlphaGo Zero has Differences
======
Only self-play
Residual Network
Single Neural Network
Simplifyed MCTS

AlhaGo Zero uses ResNets
======
![Image of ResNet](https://tareqkomboz.github.io/forkedHauptseminar/images/ResNet.png)
Source: He, Kaiming et al., 2015

AlphaGo Zero plays against itself
======
![Image of Self Play](https://tareqkomboz.github.io/forkedHauptseminar/images/AlphaZero_RL.png)
Source: Silver, David et al., 2017

The Policy Network predicts AlphaGo Zeros move
======
![Image of Policy Network](https://tareqkomboz.github.io/forkedHauptseminar/images/AlphaZero_PolicyNetwork.png)
Source: Silver, David et al., 2017

The Value Network predicts the winner
======
![Image of Value Network](https://tareqkomboz.github.io/forkedHauptseminar/images/AlphaZero_ValueNetwork.png)
Source: Silver, David et al., 2017

Results
======

AlphaGo Zero has improved
======
![Image of AlphaGo Zero Performance](https://tareqkomboz.github.io/forkedHauptseminar/images/AlphaZero_Performance.png)
Source: Silver, David et al., 2017

AlphaGo becomes more efficient
======
![Image of AlphaGo Zero Efficiency](https://tareqkomboz.github.io/forkedHauptseminar/images/Power_Consumption.png)
Source: Silver, David et al., 2017

AlphaGo Zero discovers opening patterns
======
![Image of AlphaGo Zero Openings](https://tareqkomboz.github.io/forkedHauptseminar/images/AlphaZero_Pattern.png)
Source: Silver, David et al., 2017

Humans can learn from AlphaGo Zero
======
![Image of AlphaGo Zero Openings](https://tareqkomboz.github.io/forkedHauptseminar/images/Joseki_Frequency.png)
Source: Silver, David et al., 2017

Disscussion
======
Pros
- Superior Performance
- Self-Learning
- Generalization

Cons
- Computational Resources
- Lack of Explainability

Conclusion
======
AlphaGo is the first computer program to defeat a world champion in Go.
AlphaGo Zero is able to learn Go from scratch.
Simpler algorithms can lead to better results.

Acknowledgements
======
I would like to thank Prof. Dr. Mathias Niepert and M.Sc. Marimuthu Kalimuthu, for their guidance and support throughout this project. I would also like to thank my family for their support and encouragement.

References
======
- https://www.youtube.com/watch?v=gsbkPpoxGQk
- https://www.youtube.com/watch?v=0slFo1rV0EM
- https://www.youtube.com/watch?v=Wujy7OzvdJk
- https://www.youtube.com/watch?v=Z1BELqFQZVM
- https://de.mathworks.com/discovery/convolutional-neural-network-matlab.html
- https://arxiv.org/pdf/1512.03385v1.pdf
- https://deepmind.google/technologies/alphago/
- https://deepmind.google/discover/blog/alphago-zero-starting-from-scratch/
- https://deepmind.google/discover/blog/innovations-of-alphago/

Silver, David, et al. 
"Mastering the game of Go with deep neural networks and tree search." nature 529.7587 (2016): 484-489.
"Mastering the game of go without human knowledge." nature 550.7676 (2017): 354-359.
"Mastering chess and shogi by self-play with a general reinforcement learning algorithm." arXiv preprint arXiv:1712.01815 (2017).
Blog Posts (Last accessed at 21.12.2023)
AlphaGo - Google DeepMind
AlphaGo Zero: Starting from scratch - Google DeepMind
Innovations of AlphaGo - Google DeepMind
